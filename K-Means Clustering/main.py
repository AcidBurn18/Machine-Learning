# -*- coding: utf-8 -*-
"""Task 2 Sparks

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJEhYVgWMT6xnI_iOAkGbpsRWxij0QBN

**Ansh Agrawal**

The Sparks Foundation Task 2 June Batch

Loading the Database
"""

from seaborn import load_dataset
df=load_dataset('iris')

"""Loading the Libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

df['species'].unique()

"""Dropping the  column as they are of no use in clustering our dataset"""

x=pd.DataFrame(df) #using pandas
x.drop(columns=['species'],inplace=True)
x.head()

"""**Actually, there is no need to derive the number of clusters as we already know uniques species but for the sake of learning we can derive it using the famous method Elbow Methdod**"""

temp=[]
#Range can be taken any number but should be upto 150 only as the dataset contain only 150 data so unique data ine extreme case can be 150 max
cluster_range=range(1,20) 
for i in range (1,20):
  k=KMeans(n_clusters=i)
  k=k.fit(x)
  temp.append(k.inertia_)
plt.plot(cluster_range,temp)
plt.grid()

"""Applying the k-Means Algorithm"""

#as above we can see at 3 elbow is made so in this we take clusters=3
model=KMeans(n_clusters=3)
pred=model.fit_predict(x)

pred
'''the output is array of labels sinces we choose n=3 
there are 3 diiferent labels namel 0,1,2'''

"""Plotting of the Clusters"""

y=x.iloc[:,[0,1,2,3]].values
plt.scatter(y[pred==0,0],y[pred==0,1],label="setosa")
plt.scatter(y[pred==1,0],y[pred==1,1],label="versicolor")
plt.scatter(y[pred==2,0],y[pred==2,1],label="virignica")
center=model.cluster_centers_
#print(center)
plt.scatter(center[:,0],center[:,1],color='k',label="Centroids")
plt.legend()
plt.show()



